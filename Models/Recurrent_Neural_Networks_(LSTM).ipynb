{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recurrent_Neural_Networks_(LSTM).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyCAqBpNCnPq"
      },
      "source": [
        "%%capture\n",
        "# Install the latest Tensorflow version.\n",
        "!pip install tensorflow_text\n",
        "!pip install bokeh\n",
        "!pip install simpleneighbors[annoy]\n",
        "!pip install tqdm\n",
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JlNt2Iu72or"
      },
      "source": [
        "import os,re,collections\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import GRU,LSTM, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "import tensorflow.compat.v2 as tf\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T82KUFf0s2u",
        "outputId": "381e9907-5d05-4fe2-dea3-4618eb3eb955"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vt2rQCOPz74"
      },
      "source": [
        "## ***Etape 1 : Chargement de données*** \n",
        " Nous allons extraire les données qui se trouvent dans le zip dans le drive ainsi pouvoirs les exploité facilement puis nous allons organiser les fichier de sort a ce que chaque phrase aille sa traduction dans le fichier correspondant,les phrase qui seront extraitent du fichier vont étre prétraiter "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1P-FGLG7eyj"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "#nous allons extraire nos données qui se trouvent dans un fichier zip dans notre drive \n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/rebuilt.Cross-Language-Dataset-master.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NohB7jO3jL0w"
      },
      "source": [
        "#nous allons experimenter une partie de nos donnée dans cette partie on commence par le corpus APR \n",
        "English_Dataset = tf.data.Dataset.list_files(\"/tmp/Cross-Language-Dataset-master/dataset/chunks/APR/en/*.txt\")\n",
        "Frensh_Dataset = tf.data.Dataset.list_files(\"/tmp/Cross-Language-Dataset-master/dataset/chunks/APR/fr/*.txt\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH58fu-j_in7"
      },
      "source": [
        "#nous allons organiser nos fichier text de sort a ce que les fichier en francais aille leur traduction anglaise\n",
        "English_DatasetFiles=list(English_Dataset.as_numpy_iterator())\n",
        "English_DatasetFiles.sort()\n",
        "Frensh_DatasetFiles=list(Frensh_Dataset .as_numpy_iterator())\n",
        "Frensh_DatasetFiles.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtJR_FFUUQ0d"
      },
      "source": [
        "#cette fonction permet d'extraire extrait les donnees des fichier\n",
        "def load_data(Files):\n",
        "  sentences=[]\n",
        "  for file_content in Files: \n",
        "    with open(file_content, \"r\") as f:\n",
        "      data = f.read()\n",
        "      sentences.append(data)\n",
        "  return sentences\n",
        "\n",
        "english_sentences=load_data(English_DatasetFiles)\n",
        "french_sentences=load_data(Frensh_DatasetFiles)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITcf0jAdfy6u",
        "outputId": "5df8e07f-b696-4b1e-b000-ab49e61ee31d"
      },
      "source": [
        "for i in range(5):\n",
        "  print('Sample :',i)\n",
        "  print(english_sentences[i])\n",
        "  print(french_sentences[i])\n",
        "  print('-'*50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample : 0\n",
            "the association gregory lemarchal\n",
            "\n",
            "l' association gregory lemarchal\n",
            "\n",
            "--------------------------------------------------\n",
            "Sample : 1\n",
            "after the dresden file\n",
            "\n",
            "après les dossier dresden\n",
            "\n",
            "--------------------------------------------------\n",
            "Sample : 2\n",
            "the tradition of lanfeust troy\n",
            "invention of reverse auctions\n",
            "\n",
            "la tradition lanfeust de troy\n",
            "invention des ventes aux enchères\n",
            "\n",
            "--------------------------------------------------\n",
            "Sample : 3\n",
            "the manner of dos passos\n",
            "\n",
            "la manière de dos passos\n",
            "\n",
            "--------------------------------------------------\n",
            "Sample : 4\n",
            "trace of fat in this book\n",
            "\n",
            "trace de gras dans le livre\n",
            "\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcTWq6nvOmDQ"
      },
      "source": [
        "# ***Etape 2 : Stopwords***\n",
        "première manipulation souvent effectuée dans le traitement du texte est la suppression de ce qu'on appelle en anglais les stopwords. Ce sont les mots très courants dans la langue étudiée (\"et\", \"à\", \"le\"... en français) qui n'apportent pas de valeur informative pour la compréhension du \"sens\" d'un document et corpus. Il sont très fréquents et ralentissent notre travail : nous souhaitons donc les supprimer.\n",
        "\n",
        "Il existe dans la librairie NLTK une liste par défaut des stopwords dans plusieurs Langues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0hrikyVlnAw",
        "outputId": "3f90c6e3-bdc0-472e-f18e-1af789b45aca"
      },
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "#pour supprimer les stopword de chaque langue\n",
        "def remove_stopwords(text,langue):\n",
        "    STOPWORDS = set(stopwords.words(langue))\n",
        "    \"\"\"custom function to remove the stopwords\"\"\"\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "#supprimer les stopword dans une liste de phrase\n",
        "def remove(sentences,langue):\n",
        "    values=[]\n",
        "    for text in sentences:\n",
        "       values.append(remove_stopwords(text,langue))\n",
        "    return values\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FFU2kwwlp3r"
      },
      "source": [
        "\n",
        "english_sentences=remove(english_sentences,'english')\n",
        "french_sentences=remove(french_sentences,'french')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gth9wlQr9j3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5311ba1f-f5ee-478d-dca5-2ab04c89358a"
      },
      "source": [
        "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
        "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
        "\n",
        "print('English Vocab:',len(english_words_counter))\n",
        "print('French Vocab:',len(french_words_counter))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocab: 3981\n",
            "French Vocab: 4271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGEo2THGR3hr"
      },
      "source": [
        "# ***Etape 3 :le Stemming*** \n",
        "racinisation(ou stemming en anglais). Cela consiste à ne conserver que la racine des mots étudiés. L'idée étant de supprimer les suffixes, préfixes et autres des mots afin de ne conserver que leur origine. C'est un procédé plus simple que la lemmatisation et plus rapide à effectuer puisqu'on tronque les mots essentiellement contrairement à la lemmatisation qui nécessite d'utiliser un dictionnaire.Dans notre cas, on va effectuer une racinisation parce qu'il n'existe pas de fonction de lemmatisation de corpus français dans NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3gDnA9XoD2Q"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "def stem_words_langue(text,langue):\n",
        "    stemmer2=SnowballStemmer(langue)\n",
        "    return \" \".join([stemmer2.stem(word) for word in text.split()])\n",
        "\n",
        "def stemming_langue(sentences,langue):\n",
        "  values=[]\n",
        "  for text in sentences:\n",
        "    values.append(stem_words_langue(text,langue))\n",
        "  return values\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Zds9TdSQEnn"
      },
      "source": [
        "\n",
        "english_sentences=stemming_langue(english_sentences,'english')\n",
        "french_sentences=stemming_langue(french_sentences,'french')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfDrPIYqTiPv"
      },
      "source": [
        "## ***Etape 4 : la tokenisation***\n",
        "La tokenisation est la division du texte brut en petits morceaux de mots ou de phrases, appelés jetons.Chaque phrase prend son sens par les mots qu'elle contient. Ainsi, en analysant les mots présents dans le texte, nous pouvons facilement interpréter le sens du texte. Une fois que nous avons une liste de mots, nous pouvons également utiliser des outils et des méthodes statistiques pour mieux comprendre le texte. Par exemple, nous pouvons utiliser le nombre de mots et la fréquence des mots pour découvrir l'importance d'un mot dans cette phrase ou ce document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP0AOadJ9lCz"
      },
      "source": [
        "def tokenize(x):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(x)\n",
        "  return tokenizer.texts_to_sequences(x), tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL_rK09M9vJf"
      },
      "source": [
        "def pad(x, length=None):\n",
        "  return pad_sequences(x, maxlen=length, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7_d5he_9ywE"
      },
      "source": [
        "def preprocess(x, y):\n",
        "    \"\"\"\n",
        "      Prétraiter x et y\n",
        "    : param x: Feature Liste des phrases\n",
        "    : param y: Label Liste des phrases\n",
        "    : return: Tuple de (pré-traité x, pré-traité y, x tokenizer, y tokenizer)\n",
        "    \"\"\"\n",
        "    preprocess_x, x_tk = tokenize(x)\n",
        "    preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x)\n",
        "    preprocess_y = pad(preprocess_y)\n",
        "\n",
        "    # La fonction sparse_categorical_crossentropy de Keras nécessite que les étiquettes soient en 3 dimensions\n",
        "    # Extension des dimensions\n",
        "    \n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yDJo4gD96lH"
      },
      "source": [
        "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
        "    preprocess(english_sentences, french_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk2KBv49JRa0",
        "outputId": "1df61762-7384-4372-ba00-ec9aab0e2d5c"
      },
      "source": [
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "french_vocab_size = len(french_tokenizer.word_index)\n",
        "\n",
        "print('Data Preprocessed')\n",
        "print(\"Max English sentence length:\", max_english_sequence_length)\n",
        "print(\"Max French sentence length:\", max_french_sequence_length)\n",
        "print(\"English vocabulary size:\", english_vocab_size)\n",
        "print(\"French vocabulary size:\", french_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Preprocessed\n",
            "Max English sentence length: 31\n",
            "Max French sentence length: 34\n",
            "English vocabulary size: 3616\n",
            "French vocabulary size: 3766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kxd8wRHV-OlA"
      },
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "  index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "  index_to_words[0] = '<PAD>'\n",
        "\n",
        "   # Nous prédisons la sortie pour un mot donné, puis sélectionnons la meilleure réponse\n",
        "   # En sélectionnant cette étiquette, nous énumérons le mot à partir de l'identifiant\n",
        "    \n",
        "  return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkGroinK-g_9"
      },
      "source": [
        "# Le reshaping l'entrée pour travailler avec un RNN de base\n",
        "\n",
        "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzq41ASNU-pX"
      },
      "source": [
        "# ***Etape 5 les Word embedding*** \n",
        "Nous allons utilisée un prétrained model Glove word embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCwMiNIc56t4",
        "outputId": "9820dc5e-53be-43c4-f2b0-6a05e10dd931"
      },
      "source": [
        "glove_dir = '/content/drive/MyDrive/glove/'\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByXen8xW59C4"
      },
      "source": [
        "embedding_dim = 100\n",
        "max_words = english_vocab_size+1\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in english_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5qUAc6N-WKW"
      },
      "source": [
        "def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \"\"\"\n",
        "     Créer et entraîner un modèle RNN à l'aide de l'incorporation de mots sur x et y\n",
        "     \n",
        "     : param input_shape: Tuple de la forme d'entrée\n",
        "     : param output_sequence_length: Longueur de la séquence de sortie\n",
        "     : param english_vocab_size: Nombre de mots anglais uniques dans le jeu de données\n",
        "     : param french_vocab_size: Nombre de mots français uniques dans le jeu de données\n",
        "     : return: modèle Keras construit, mais pas entraîné\n",
        "     \"\"\"\n",
        "    # Hyperparamètres\n",
        "    learning_rate = 0.005\n",
        "    \n",
        "    # Couches\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(english_vocab_size, 100, weights=[embedding_matrix],input_length=input_shape[1],input_shape=input_shape[1:]))\n",
        "    model.add(LSTM(256, return_sequences=True))    \n",
        "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \n",
        "     # Compilation du modèle\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer='Adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-forzESg-j94"
      },
      "source": [
        "simple_rnn_model = embed_model(\n",
        "    tmp_x.shape,\n",
        "    preproc_french_sentences.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(french_tokenizer.word_index)+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9KkmafL-rjI",
        "outputId": "46956ac9-a79d-437f-d213-0afa2b99946a"
      },
      "source": [
        "simple_rnn_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 844, 100)          517800    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 844, 256)          365568    \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 844, 1024)         263168    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 844, 1024)         0         \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 844, 4944)         5067600   \n",
            "=================================================================\n",
            "Total params: 6,214,136\n",
            "Trainable params: 6,214,136\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL_BkCJhS0p_",
        "outputId": "6ada93ff-af30-4e12-b3cc-9f85e7e4b688"
      },
      "source": [
        "history=simple_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=200, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 1.5069 - accuracy: 0.8495 - val_loss: 1.7555 - val_accuracy: 0.8357\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 1s 196ms/step - loss: 1.4865 - accuracy: 0.8499 - val_loss: 1.7378 - val_accuracy: 0.8362\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 1s 200ms/step - loss: 1.4667 - accuracy: 0.8503 - val_loss: 1.7196 - val_accuracy: 0.8363\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 1s 200ms/step - loss: 1.4518 - accuracy: 0.8502 - val_loss: 1.7015 - val_accuracy: 0.8358\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 1s 196ms/step - loss: 1.4383 - accuracy: 0.8505 - val_loss: 1.6855 - val_accuracy: 0.8355\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 1s 203ms/step - loss: 1.4208 - accuracy: 0.8503 - val_loss: 1.6703 - val_accuracy: 0.8354\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 1s 199ms/step - loss: 1.4051 - accuracy: 0.8503 - val_loss: 1.6541 - val_accuracy: 0.8353\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 1s 198ms/step - loss: 1.3867 - accuracy: 0.8503 - val_loss: 1.6367 - val_accuracy: 0.8354\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 1.3683 - accuracy: 0.8504 - val_loss: 1.6206 - val_accuracy: 0.8356\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 1.3503 - accuracy: 0.8505 - val_loss: 1.6054 - val_accuracy: 0.8357\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 1s 200ms/step - loss: 1.3345 - accuracy: 0.8502 - val_loss: 1.5918 - val_accuracy: 0.8357\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 1s 199ms/step - loss: 1.3173 - accuracy: 0.8502 - val_loss: 1.5790 - val_accuracy: 0.8358\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 1s 198ms/step - loss: 1.3010 - accuracy: 0.8505 - val_loss: 1.5657 - val_accuracy: 0.8358\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 1s 198ms/step - loss: 1.2859 - accuracy: 0.8505 - val_loss: 1.5497 - val_accuracy: 0.8363\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 1.2678 - accuracy: 0.8509 - val_loss: 1.5318 - val_accuracy: 0.8356\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 1s 203ms/step - loss: 1.2509 - accuracy: 0.8509 - val_loss: 1.5148 - val_accuracy: 0.8353\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 1s 199ms/step - loss: 1.2346 - accuracy: 0.8508 - val_loss: 1.5019 - val_accuracy: 0.8353\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 1.2191 - accuracy: 0.8512 - val_loss: 1.4933 - val_accuracy: 0.8354\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 1s 200ms/step - loss: 1.2040 - accuracy: 0.8511 - val_loss: 1.4890 - val_accuracy: 0.8356\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 1s 198ms/step - loss: 1.1906 - accuracy: 0.8510 - val_loss: 1.4856 - val_accuracy: 0.8357\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 1s 198ms/step - loss: 1.1786 - accuracy: 0.8509 - val_loss: 1.4840 - val_accuracy: 0.8363\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 1.1676 - accuracy: 0.8512 - val_loss: 1.4856 - val_accuracy: 0.8363\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 1s 201ms/step - loss: 1.1574 - accuracy: 0.8511 - val_loss: 1.4893 - val_accuracy: 0.8369\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 1s 200ms/step - loss: 1.1484 - accuracy: 0.8512 - val_loss: 1.4933 - val_accuracy: 0.8369\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 1.1413 - accuracy: 0.8515 - val_loss: 1.4978 - val_accuracy: 0.8369\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 1s 201ms/step - loss: 1.1329 - accuracy: 0.8515 - val_loss: 1.5019 - val_accuracy: 0.8376\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 1.1263 - accuracy: 0.8522 - val_loss: 1.5052 - val_accuracy: 0.8382\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 1s 204ms/step - loss: 1.1197 - accuracy: 0.8520 - val_loss: 1.5098 - val_accuracy: 0.8383\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 1.1130 - accuracy: 0.8524 - val_loss: 1.5163 - val_accuracy: 0.8384\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 1s 203ms/step - loss: 1.1072 - accuracy: 0.8526 - val_loss: 1.5223 - val_accuracy: 0.8386\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 1.1019 - accuracy: 0.8521 - val_loss: 1.5255 - val_accuracy: 0.8386\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 1s 212ms/step - loss: 1.0952 - accuracy: 0.8527 - val_loss: 1.5296 - val_accuracy: 0.8386\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 1s 201ms/step - loss: 1.0914 - accuracy: 0.8525 - val_loss: 1.5312 - val_accuracy: 0.8386\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 1s 198ms/step - loss: 1.0841 - accuracy: 0.8529 - val_loss: 1.5355 - val_accuracy: 0.8389\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 1s 201ms/step - loss: 1.0787 - accuracy: 0.8529 - val_loss: 1.5438 - val_accuracy: 0.8387\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 1s 205ms/step - loss: 1.0744 - accuracy: 0.8530 - val_loss: 1.5479 - val_accuracy: 0.8389\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 1s 199ms/step - loss: 1.0685 - accuracy: 0.8533 - val_loss: 1.5513 - val_accuracy: 0.8393\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 1.0632 - accuracy: 0.8533 - val_loss: 1.5565 - val_accuracy: 0.8392\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 1s 241ms/step - loss: 1.0582 - accuracy: 0.8535 - val_loss: 1.5598 - val_accuracy: 0.8390\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 1.0525 - accuracy: 0.8539 - val_loss: 1.5629 - val_accuracy: 0.8388\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 1s 204ms/step - loss: 1.0473 - accuracy: 0.8536 - val_loss: 1.5718 - val_accuracy: 0.8387\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 1s 201ms/step - loss: 1.0422 - accuracy: 0.8533 - val_loss: 1.5765 - val_accuracy: 0.8388\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 1s 203ms/step - loss: 1.0367 - accuracy: 0.8535 - val_loss: 1.5800 - val_accuracy: 0.8387\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 1s 203ms/step - loss: 1.0313 - accuracy: 0.8538 - val_loss: 1.5853 - val_accuracy: 0.8389\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 1.0248 - accuracy: 0.8537 - val_loss: 1.5871 - val_accuracy: 0.8388\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 1.0190 - accuracy: 0.8542 - val_loss: 1.5934 - val_accuracy: 0.8390\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 1s 212ms/step - loss: 1.0143 - accuracy: 0.8539 - val_loss: 1.5978 - val_accuracy: 0.8390\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 1.0087 - accuracy: 0.8545 - val_loss: 1.5993 - val_accuracy: 0.8389\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 1.0021 - accuracy: 0.8546 - val_loss: 1.6040 - val_accuracy: 0.8391\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.9957 - accuracy: 0.8547 - val_loss: 1.6088 - val_accuracy: 0.8390\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 1s 197ms/step - loss: 0.9885 - accuracy: 0.8551 - val_loss: 1.6116 - val_accuracy: 0.8389\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.9830 - accuracy: 0.8555 - val_loss: 1.6174 - val_accuracy: 0.8393\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 1s 203ms/step - loss: 0.9759 - accuracy: 0.8555 - val_loss: 1.6197 - val_accuracy: 0.8390\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 1s 200ms/step - loss: 0.9702 - accuracy: 0.8559 - val_loss: 1.6228 - val_accuracy: 0.8389\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.9627 - accuracy: 0.8561 - val_loss: 1.6263 - val_accuracy: 0.8389\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 0.9567 - accuracy: 0.8564 - val_loss: 1.6293 - val_accuracy: 0.8393\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 0.9483 - accuracy: 0.8565 - val_loss: 1.6318 - val_accuracy: 0.8399\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 1s 204ms/step - loss: 0.9418 - accuracy: 0.8570 - val_loss: 1.6346 - val_accuracy: 0.8399\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 1s 205ms/step - loss: 0.9338 - accuracy: 0.8575 - val_loss: 1.6387 - val_accuracy: 0.8399\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 0.9272 - accuracy: 0.8576 - val_loss: 1.6427 - val_accuracy: 0.8400\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 0.9205 - accuracy: 0.8578 - val_loss: 1.6471 - val_accuracy: 0.8402\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 1s 199ms/step - loss: 0.9134 - accuracy: 0.8580 - val_loss: 1.6503 - val_accuracy: 0.8400\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.9047 - accuracy: 0.8586 - val_loss: 1.6539 - val_accuracy: 0.8403\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 1s 203ms/step - loss: 0.8977 - accuracy: 0.8587 - val_loss: 1.6583 - val_accuracy: 0.8401\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 1s 204ms/step - loss: 0.8884 - accuracy: 0.8589 - val_loss: 1.6610 - val_accuracy: 0.8402\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 1s 203ms/step - loss: 0.8808 - accuracy: 0.8592 - val_loss: 1.6675 - val_accuracy: 0.8407\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.8734 - accuracy: 0.8604 - val_loss: 1.6674 - val_accuracy: 0.8402\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 1s 200ms/step - loss: 0.8647 - accuracy: 0.8603 - val_loss: 1.6745 - val_accuracy: 0.8406\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 0.8551 - accuracy: 0.8609 - val_loss: 1.6768 - val_accuracy: 0.8403\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 1s 204ms/step - loss: 0.8463 - accuracy: 0.8614 - val_loss: 1.6816 - val_accuracy: 0.8405\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 0.8380 - accuracy: 0.8617 - val_loss: 1.6854 - val_accuracy: 0.8405\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.8315 - accuracy: 0.8620 - val_loss: 1.6891 - val_accuracy: 0.8409\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 1s 204ms/step - loss: 0.8212 - accuracy: 0.8622 - val_loss: 1.6925 - val_accuracy: 0.8410\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 1s 205ms/step - loss: 0.8120 - accuracy: 0.8628 - val_loss: 1.6990 - val_accuracy: 0.8413\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.8039 - accuracy: 0.8631 - val_loss: 1.7021 - val_accuracy: 0.8410\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 1s 201ms/step - loss: 0.7949 - accuracy: 0.8637 - val_loss: 1.7062 - val_accuracy: 0.8409\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.7834 - accuracy: 0.8654 - val_loss: 1.7122 - val_accuracy: 0.8410\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 1s 214ms/step - loss: 0.7760 - accuracy: 0.8660 - val_loss: 1.7142 - val_accuracy: 0.8413\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.7672 - accuracy: 0.8674 - val_loss: 1.7184 - val_accuracy: 0.8411\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.7554 - accuracy: 0.8674 - val_loss: 1.7240 - val_accuracy: 0.8420\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.7458 - accuracy: 0.8687 - val_loss: 1.7238 - val_accuracy: 0.8413\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 1s 201ms/step - loss: 0.7369 - accuracy: 0.8695 - val_loss: 1.7257 - val_accuracy: 0.8413\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 1s 205ms/step - loss: 0.7290 - accuracy: 0.8706 - val_loss: 1.7326 - val_accuracy: 0.8422\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.7190 - accuracy: 0.8708 - val_loss: 1.7333 - val_accuracy: 0.8420\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 1s 205ms/step - loss: 0.7079 - accuracy: 0.8719 - val_loss: 1.7332 - val_accuracy: 0.8419\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 1s 200ms/step - loss: 0.6963 - accuracy: 0.8735 - val_loss: 1.7364 - val_accuracy: 0.8421\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.6870 - accuracy: 0.8742 - val_loss: 1.7390 - val_accuracy: 0.8417\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.6774 - accuracy: 0.8766 - val_loss: 1.7433 - val_accuracy: 0.8426\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 1s 214ms/step - loss: 0.6680 - accuracy: 0.8777 - val_loss: 1.7439 - val_accuracy: 0.8432\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 1s 203ms/step - loss: 0.6547 - accuracy: 0.8792 - val_loss: 1.7460 - val_accuracy: 0.8417\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.6507 - accuracy: 0.8797 - val_loss: 1.7560 - val_accuracy: 0.8426\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.6382 - accuracy: 0.8821 - val_loss: 1.7515 - val_accuracy: 0.8426\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 1s 209ms/step - loss: 0.6287 - accuracy: 0.8833 - val_loss: 1.7567 - val_accuracy: 0.8438\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.6173 - accuracy: 0.8850 - val_loss: 1.7583 - val_accuracy: 0.8431\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 1s 203ms/step - loss: 0.6068 - accuracy: 0.8869 - val_loss: 1.7588 - val_accuracy: 0.8435\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.5979 - accuracy: 0.8889 - val_loss: 1.7654 - val_accuracy: 0.8443\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.5893 - accuracy: 0.8901 - val_loss: 1.7598 - val_accuracy: 0.8426\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.5778 - accuracy: 0.8929 - val_loss: 1.7707 - val_accuracy: 0.8441\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 1s 212ms/step - loss: 0.5715 - accuracy: 0.8924 - val_loss: 1.7628 - val_accuracy: 0.8431\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.5618 - accuracy: 0.8961 - val_loss: 1.7715 - val_accuracy: 0.8446\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.5466 - accuracy: 0.8963 - val_loss: 1.7696 - val_accuracy: 0.8442\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 1s 209ms/step - loss: 0.5370 - accuracy: 0.8992 - val_loss: 1.7792 - val_accuracy: 0.8446\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 1s 212ms/step - loss: 0.5281 - accuracy: 0.8994 - val_loss: 1.7744 - val_accuracy: 0.8441\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.5183 - accuracy: 0.9030 - val_loss: 1.7799 - val_accuracy: 0.8450\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 1s 204ms/step - loss: 0.5096 - accuracy: 0.9031 - val_loss: 1.7786 - val_accuracy: 0.8445\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 1s 214ms/step - loss: 0.5017 - accuracy: 0.9048 - val_loss: 1.7846 - val_accuracy: 0.8449\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.4923 - accuracy: 0.9059 - val_loss: 1.7846 - val_accuracy: 0.8444\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 1s 215ms/step - loss: 0.4814 - accuracy: 0.9081 - val_loss: 1.7842 - val_accuracy: 0.8439\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.4714 - accuracy: 0.9102 - val_loss: 1.7895 - val_accuracy: 0.8449\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.4634 - accuracy: 0.9103 - val_loss: 1.7848 - val_accuracy: 0.8447\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.4579 - accuracy: 0.9114 - val_loss: 1.7914 - val_accuracy: 0.8449\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.4486 - accuracy: 0.9130 - val_loss: 1.7910 - val_accuracy: 0.8451\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.4393 - accuracy: 0.9151 - val_loss: 1.7937 - val_accuracy: 0.8451\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.4312 - accuracy: 0.9159 - val_loss: 1.7937 - val_accuracy: 0.8449\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 1s 215ms/step - loss: 0.4216 - accuracy: 0.9176 - val_loss: 1.7952 - val_accuracy: 0.8447\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.4158 - accuracy: 0.9184 - val_loss: 1.7983 - val_accuracy: 0.8453\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.4078 - accuracy: 0.9200 - val_loss: 1.7988 - val_accuracy: 0.8448\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 1s 212ms/step - loss: 0.4011 - accuracy: 0.9210 - val_loss: 1.8024 - val_accuracy: 0.8446\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 1s 203ms/step - loss: 0.3943 - accuracy: 0.9209 - val_loss: 1.8031 - val_accuracy: 0.8452\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.3873 - accuracy: 0.9240 - val_loss: 1.8055 - val_accuracy: 0.8456\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.3815 - accuracy: 0.9233 - val_loss: 1.8052 - val_accuracy: 0.8449\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.3717 - accuracy: 0.9258 - val_loss: 1.8099 - val_accuracy: 0.8452\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.3691 - accuracy: 0.9252 - val_loss: 1.8084 - val_accuracy: 0.8451\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.3627 - accuracy: 0.9264 - val_loss: 1.8110 - val_accuracy: 0.8448\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 1s 215ms/step - loss: 0.3559 - accuracy: 0.9282 - val_loss: 1.8102 - val_accuracy: 0.8446\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.3506 - accuracy: 0.9287 - val_loss: 1.8139 - val_accuracy: 0.8453\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.3430 - accuracy: 0.9296 - val_loss: 1.8132 - val_accuracy: 0.8445\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3361 - accuracy: 0.9309 - val_loss: 1.8170 - val_accuracy: 0.8452\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.3330 - accuracy: 0.9307 - val_loss: 1.8167 - val_accuracy: 0.8449\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 1s 215ms/step - loss: 0.3272 - accuracy: 0.9335 - val_loss: 1.8203 - val_accuracy: 0.8454\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.3220 - accuracy: 0.9320 - val_loss: 1.8193 - val_accuracy: 0.8448\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3161 - accuracy: 0.9340 - val_loss: 1.8233 - val_accuracy: 0.8460\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.3122 - accuracy: 0.9344 - val_loss: 1.8218 - val_accuracy: 0.8446\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 1s 205ms/step - loss: 0.3064 - accuracy: 0.9369 - val_loss: 1.8250 - val_accuracy: 0.8455\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.3009 - accuracy: 0.9357 - val_loss: 1.8236 - val_accuracy: 0.8447\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.2965 - accuracy: 0.9378 - val_loss: 1.8252 - val_accuracy: 0.8454\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.2909 - accuracy: 0.9383 - val_loss: 1.8259 - val_accuracy: 0.8451\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.2873 - accuracy: 0.9393 - val_loss: 1.8278 - val_accuracy: 0.8456\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.2826 - accuracy: 0.9395 - val_loss: 1.8285 - val_accuracy: 0.8449\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.2788 - accuracy: 0.9408 - val_loss: 1.8310 - val_accuracy: 0.8454\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.2736 - accuracy: 0.9416 - val_loss: 1.8316 - val_accuracy: 0.8447\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.2692 - accuracy: 0.9425 - val_loss: 1.8346 - val_accuracy: 0.8454\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.2667 - accuracy: 0.9429 - val_loss: 1.8334 - val_accuracy: 0.8456\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.2609 - accuracy: 0.9443 - val_loss: 1.8344 - val_accuracy: 0.8454\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.2561 - accuracy: 0.9448 - val_loss: 1.8349 - val_accuracy: 0.8455\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 1s 212ms/step - loss: 0.2561 - accuracy: 0.9443 - val_loss: 1.8369 - val_accuracy: 0.8452\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.2525 - accuracy: 0.9453 - val_loss: 1.8383 - val_accuracy: 0.8455\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.2454 - accuracy: 0.9467 - val_loss: 1.8397 - val_accuracy: 0.8457\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 1s 212ms/step - loss: 0.2441 - accuracy: 0.9464 - val_loss: 1.8398 - val_accuracy: 0.8452\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.2376 - accuracy: 0.9477 - val_loss: 1.8430 - val_accuracy: 0.8457\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.2362 - accuracy: 0.9484 - val_loss: 1.8413 - val_accuracy: 0.8452\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.2331 - accuracy: 0.9486 - val_loss: 1.8449 - val_accuracy: 0.8455\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.2318 - accuracy: 0.9483 - val_loss: 1.8443 - val_accuracy: 0.8453\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.2250 - accuracy: 0.9503 - val_loss: 1.8479 - val_accuracy: 0.8454\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.2233 - accuracy: 0.9501 - val_loss: 1.8467 - val_accuracy: 0.8451\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.2199 - accuracy: 0.9515 - val_loss: 1.8503 - val_accuracy: 0.8459\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.2202 - accuracy: 0.9499 - val_loss: 1.8503 - val_accuracy: 0.8453\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.2138 - accuracy: 0.9518 - val_loss: 1.8531 - val_accuracy: 0.8455\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.2109 - accuracy: 0.9523 - val_loss: 1.8530 - val_accuracy: 0.8450\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.2065 - accuracy: 0.9535 - val_loss: 1.8559 - val_accuracy: 0.8456\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 1s 205ms/step - loss: 0.2051 - accuracy: 0.9531 - val_loss: 1.8552 - val_accuracy: 0.8451\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.2038 - accuracy: 0.9539 - val_loss: 1.8584 - val_accuracy: 0.8461\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.1993 - accuracy: 0.9545 - val_loss: 1.8574 - val_accuracy: 0.8457\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.1987 - accuracy: 0.9556 - val_loss: 1.8604 - val_accuracy: 0.8462\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.1939 - accuracy: 0.9561 - val_loss: 1.8613 - val_accuracy: 0.8459\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.1934 - accuracy: 0.9569 - val_loss: 1.8646 - val_accuracy: 0.8463\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.1899 - accuracy: 0.9558 - val_loss: 1.8620 - val_accuracy: 0.8458\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.1878 - accuracy: 0.9572 - val_loss: 1.8657 - val_accuracy: 0.8464\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.1868 - accuracy: 0.9573 - val_loss: 1.8651 - val_accuracy: 0.8459\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.1861 - accuracy: 0.9575 - val_loss: 1.8684 - val_accuracy: 0.8467\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.1811 - accuracy: 0.9579 - val_loss: 1.8646 - val_accuracy: 0.8458\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.1790 - accuracy: 0.9590 - val_loss: 1.8713 - val_accuracy: 0.8463\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.1786 - accuracy: 0.9582 - val_loss: 1.8677 - val_accuracy: 0.8456\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.1744 - accuracy: 0.9600 - val_loss: 1.8719 - val_accuracy: 0.8462\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.1719 - accuracy: 0.9599 - val_loss: 1.8706 - val_accuracy: 0.8456\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.1716 - accuracy: 0.9607 - val_loss: 1.8745 - val_accuracy: 0.8461\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.1690 - accuracy: 0.9607 - val_loss: 1.8714 - val_accuracy: 0.8455\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.1694 - accuracy: 0.9615 - val_loss: 1.8748 - val_accuracy: 0.8463\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 1s 205ms/step - loss: 0.1636 - accuracy: 0.9616 - val_loss: 1.8733 - val_accuracy: 0.8460\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.1638 - accuracy: 0.9620 - val_loss: 1.8735 - val_accuracy: 0.8462\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.1618 - accuracy: 0.9621 - val_loss: 1.8766 - val_accuracy: 0.8465\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 1s 205ms/step - loss: 0.1596 - accuracy: 0.9631 - val_loss: 1.8756 - val_accuracy: 0.8455\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.1585 - accuracy: 0.9635 - val_loss: 1.8814 - val_accuracy: 0.8466\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.1573 - accuracy: 0.9631 - val_loss: 1.8785 - val_accuracy: 0.8457\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 1s 215ms/step - loss: 0.1535 - accuracy: 0.9642 - val_loss: 1.8797 - val_accuracy: 0.8455\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.1501 - accuracy: 0.9641 - val_loss: 1.8824 - val_accuracy: 0.8461\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 1s 209ms/step - loss: 0.1503 - accuracy: 0.9649 - val_loss: 1.8821 - val_accuracy: 0.8454\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.1483 - accuracy: 0.9658 - val_loss: 1.8832 - val_accuracy: 0.8465\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.1453 - accuracy: 0.9662 - val_loss: 1.8812 - val_accuracy: 0.8461\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 1s 209ms/step - loss: 0.1439 - accuracy: 0.9666 - val_loss: 1.8827 - val_accuracy: 0.8462\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.1410 - accuracy: 0.9673 - val_loss: 1.8864 - val_accuracy: 0.8463\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.1421 - accuracy: 0.9672 - val_loss: 1.8867 - val_accuracy: 0.8459\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.1397 - accuracy: 0.9674 - val_loss: 1.8896 - val_accuracy: 0.8457\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.1379 - accuracy: 0.9678 - val_loss: 1.8899 - val_accuracy: 0.8454\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.1350 - accuracy: 0.9686 - val_loss: 1.8912 - val_accuracy: 0.8455\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.1353 - accuracy: 0.9684 - val_loss: 1.8942 - val_accuracy: 0.8462\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 1s 209ms/step - loss: 0.1323 - accuracy: 0.9695 - val_loss: 1.8955 - val_accuracy: 0.8462\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.1325 - accuracy: 0.9688 - val_loss: 1.8985 - val_accuracy: 0.8466\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.1297 - accuracy: 0.9692 - val_loss: 1.8962 - val_accuracy: 0.8459\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 1s 214ms/step - loss: 0.1284 - accuracy: 0.9692 - val_loss: 1.8961 - val_accuracy: 0.8460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rxWXriDddQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c188d402-6720-4e43-b4e9-6b4c4d4d3c3c"
      },
      "source": [
        "scores =simple_rnn_model.evaluate(tmp_x, preproc_french_sentences, verbose=0)\n",
        "# Displays the accuracy of correct sentiment prediction over test data\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 95.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTx4ARR9NGgl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "e56706d2-a38d-409e-995a-6c27365a3e94"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5fn//9fFLosLBDeQRYviAhINuKCI+y7Uaj/SaOFDW0Rt3T5qbW2F2trW6q8/6sOt1KVqo2CtttpKXXABt0rYBVGRpYIoGASCKEu4vn/cZ2AImWRmMpmZTN7Px2MemTlzzpkrZ5Jr7rnu+9zH3B0RESlczXIdgIiINCwlehGRAqdELyJS4JToRUQKnBK9iEiBU6IXESlwSvSSEjObZGbDM71uLpnZEjM7pQH262b2jej+fWb282TWTeN1Ss3shXTjrGW/g81sWab3K9nXItcBSMMzs/VxD9sCG4Gq6PGl7l6W7L7c/cyGWLfQufvoTOzHzHoAi4GW7r4l2ncZkPR7KE2PEn0T4O7tY/fNbAnwfXd/qfp6ZtYiljxEpHCodNOExb6am9mPzexT4CEz28PM/mlmq8zsi+h+17htXjWz70f3R5jZ62Z2R7TuYjM7M811e5rZFDOrNLOXzOxuM/tLgriTifGXZvZGtL8XzKwo7vlLzGypmVWY2U21HJ+jzOxTM2set+ybZjYnuj/AzN4yszVmtsLM7jKzVgn29Wcz+1Xc4+ujbT4xs5HV1j3bzGaa2Toz+9jMxsY9PSX6ucbM1pvZMbFjG7f9sWY2zczWRj+PTfbY1MbMDo62X2Nm88zsvLjnzjKz+dE+l5vZddHyouj9WWNmq81sqpkp72SZDrjsDXQEugOjCH8TD0WPuwFfAXfVsv1RwPtAEfA74AEzszTWfQx4B+gEjAUuqeU1k4nxO8D/AnsCrYBY4jkEuDfa/77R63WlBu7+H+BL4KRq+30sul8FXBP9PscAJwOX1xI3UQxnRPGcCvQCqvcPfAl8F9gdOBu4zMyGRs8Nin7u7u7t3f2tavvuCPwLuDP63X4P/MvMOlX7HXY6NnXE3BJ4Fngh2u5HQJmZHRSt8gChDNgBOAx4OVr+f8AyoDOwF/BTQPOuZJkSvWwFxrj7Rnf/yt0r3P1v7r7B3SuBW4ETatl+qbv/yd2rgIeBfQj/0Emva2bdgP7Aze6+yd1fB55J9IJJxviQu3/g7l8BTwD9ouUXAP909ynuvhH4eXQMEnkcGAZgZh2As6JluPt0d3/b3be4+xLgjzXEUZNvR/G96+5fEj7Y4n+/V919rrtvdfc50esls18IHwwfuvujUVyPAwuAc+PWSXRsanM00B74bfQevQz8k+jYAJuBQ8xsV3f/wt1nxC3fB+ju7pvdfaprgq2sU6KXVe7+deyBmbU1sz9GpY11hFLB7vHli2o+jd1x9w3R3fYprrsvsDpuGcDHiQJOMsZP4+5viItp3/h9R4m2ItFrEVrv55tZa+B8YIa7L43iODAqS3waxfFrQuu+LjvEACyt9vsdZWavRKWptcDoJPcb2/fSasuWAl3iHic6NnXG7O7xH4rx+/0W4UNwqZm9ZmbHRMtvBxYCL5jZIjO7MblfQzJJiV6qt67+DzgIOMrdd2V7qSBROSYTVgAdzaxt3LL9alm/PjGuiN939JqdEq3s7vMJCe1MdizbQCgBLQB6RXH8NJ0YCOWneI8RvtHs5+67AffF7beu1vAnhJJWvG7A8iTiqmu/+1Wrr2/br7tPc/chhLLO3wnfFHD3Snf/P3ffHzgPuNbMTq5nLJIiJXqprgOh5r0mqveOaegXjFrI5cBYM2sVtQbPrWWT+sT4JHCOmR0XdZzeQt3/B48BVxE+UP5aLY51wHoz6w1clmQMTwAjzOyQ6IOmevwdCN9wvjazAYQPmJhVhFLT/gn2/RxwoJl9x8xamNn/AIcQyiz18R9C6/8GM2tpZoMJ79GE6D0rNbPd3H0z4ZhsBTCzc8zsG1FfzFpCv0ZtpTJpAEr0Ut04YBfgc+Bt4N9Zet1SQodmBfArYCJhvH9N0o7R3ecBVxCS9wrgC0JnYW1iNfKX3f3zuOXXEZJwJfCnKOZkYpgU/Q4vE8oaL1db5XLgFjOrBG4mah1H224g9Em8EY1kObraviuAcwjfeiqAG4BzqsWdMnffREjsZxKO+z3Ad919QbTKJcCSqIQ1mvB+QuhsfglYD7wF3OPur9QnFkmdqV9E8pGZTQQWuHuDf6MQKXRq0UteMLP+ZnaAmTWLhh8OIdR6RaSedGas5Iu9gacIHaPLgMvcfWZuQxIpDCrdiIgUOJVuREQKXF6WboqKirxHjx65DkNEpNGYPn365+7euabn8jLR9+jRg/Ly8lyHISLSaJhZ9TOit1HpRkSkwCnRi4gUOCV6EZECp0QvIlLglOhFRAqcEr2ISIFTohcRKXB5OY5eRKRQucPq1fDxxzBtGlRWwsEHQ7t20Lo1HHVU5l9TiV5EJIOqqmDxYtiwAT78EObOha+/hjVrYOlSeOedkOhrstde8OmnNT9XH0r0IiLVbN0KmzaFnxMnwsKF0LdvaI0vXgyzZsHGjeH5igrYYw/Ye29YsQLefnvHRG4GrVrBrrtCly4wdCj06RPuFxfD7rvD+++H/bVooIysRC8iBWXzZli7FoqKYMECmDIF+veH5ctDqWSPPeCDD0KyPvTQkNBnzgzLd9sNvvwSZswILfBmzUIyNwtJPmb//aFDh3C/Y8dQhpk+PbTIzz0XBg0Kz3frBv36hZJMbYqSvfR7mpToRSSvuYebGSxaFFrXq1bBW2/B559D797w7ruhVdy6dUjuGzbAAQeE9Wuaib1du5CAn3wytKIHDIB160LCbt0avv3tkKS//BJOPz3UzRcsCM/tu2/4QGhMlOhFJGfWrYMvvoD160Mr+osv4KuvdmxRl5eHUsguu4TEG9O+PXTuDE88AfvtB0ccEcofxx0XyihvvBESdmlpaL0XFcEJJ4R9dOgQyimxDwGzumPt169hjkE2KNGLSMatWRPKIe3bh87JKVNCEl67Fl5/PSyrqoLZs0NppLoePUIZZONGOOecUM9evx4OOSSUWzp2hF69Qmv8q6+gTZvak/Whh26/36bN9vvJJPhCoEQvIrXatAneey/c9tgjtII/+yyMDvnss+33Y7dNm0KruaaSScuWcPTR4QNg82b4+c+he/dQEjn8cNhnH2jePLXSyC67ZO53LVRK9CJNxJYtYcz27ruHYX8ffwx77hlayp98sv22cmVoeX/44fbRIIm0axda3nvvDQcdBIMHh6TdsWPoAN24MbzuoEHhdd1DspfsUqIXKQBVVaGFvHUrTJ0K//1vePzmmyF577JL6Lz84otQ7tiypeb9tGgREveuu4byyamnhgTdo0cYXlhZGdbbe++wXvv22foNpT6U6EXyXEVFOOFm5Up4+ulQk27fHubPD/erqkLde926nbfdc0/4xjfCPoYODTXulStDfbtXrzB6pX37MJJk332hU6fQASqFRYleJA9UVGwfXbJkSei8jK97xzRvHlrdGzeGsdy77RZa5xddFFrdmzaFGvghh4SOxi5dmk6HoySmRC/SQNzD6e/uIfFOnBjGewPMmxdKKlu37pzMAQ47LCTufv3C/Q4dwmiRM88MwwQ3bar7JByRGCV6kRRVVYVad1FRGF0yZ06oaf/zn/DssyGxt2gRTuaZPz9s065dWLdly5DcDzooJHKzMP67V69wUs6++4ax4R071h6DkrykQoleJIH160NC32+/kLRnzIC2beHaa8Op9H37hnlPYh2UEM6w7NAhlFO6dIErrgjJ/fXX4YILwphwUDlFsqvORG9mDwLnACvd/bAanr8eKI3b38FAZ3dfbWZLgEqgCtji7iWZClwk0778Eh54ICT1gQNDkl6yJNS/n3suJH0Ire0bbwxnXg4dCuefH7bt0yck/5r84AdZ+zVEdpJMi/7PwF3AIzU96e63A7cDmNm5wDXuHj8J54nu/nk946xTVRXccgucdVbDzOcsheGjj+DRR0OH5dq1YRTLokUhua9aFVrxsQms9t4bLrkEHnkEjj0WfvrTsM0JJ4QTe0QaizoTvbtPMbMeSe5vGPB4fQJKV2Vl+Ad+8MEwi9yee+YiCsk3y5eHjs7Vq8Mp+b/61Y6lln33DZ2dBx4Y6uylpaF2/sILcMYZIaHfcUc4I1TDDqWxMq/pPOXqK4VE/8+aSjdx67QFlgHfiLXozWwx8AXgwB/dfXwt248CRgF069btyKVLlyb/W0Rmzgwtr2OOCf+oDTW3s+Sf2Pzhn3wShia+9lq4LV6843qDBsH994ezPtu0Ca3z5s1zE7NIJpnZ9ETl8UymwnOBN6qVbY5z9+VmtifwopktcPcpNW0cfQiMBygpKan706cGxcVw330wYgT87Gfw29+msxfJZ7G5wSsrwwf7bbfBiy/ufKZnx44hqV95ZZiudtddQ6t9773D9r165SZ+kVzIZKK/iGplG3dfHv1caWZPAwOAGhN9pgwfHq7wctttYQTE+ec35KtJNmzZEjo+H34YJkwIZ4PGdOoEP/pROHGoVatQYhk4MMxWqFKLSJCRRG9muwEnABfHLWsHNHP3yuj+acAtmXi9uowbF4bCjRgRTlTp3TsbryqZ9N//wr33hjLMvHmhE7RdOxg2LAx3bNs2nNp/6qnbr/QjIjVLZnjl48BgoMjMlgFjgJYA7n5ftNo3gRfcPe6yAOwFPG1hwHAL4DF3/3fmQk+sdetw5Zgjjwwt+nfe0eRL+a6qCl55JZRhJk8OH9Rm4SISw4bBySeHK/0oqYukLqnO2GwrKSnx8vLyeu/n5ZdDi++CC8JXfp2kkl/cw+XZXngB7r47dJDG5is/5ZTwjaxbt1xHKdI4ZKszNu+cdBL85jfw4x+HubGvuy7XEcmXX8Lzz8M//hFa7ytWhOVHHBHmgjn77FCiEZHMKehED3D99WFWwBtugJ494VvfynVETc/MmfD44+GycVOmhCl399gDTjstlGROPjnMxCgiDaPgE71ZGK2xbBlcfHE4QeaYY3IdVWGrrITx4+HVV8Mc6VOmhBExvXuHqQC++c1Qe9eVhkSyo+ATPYSr6/zjHyHBn3deuNLON76R66gKx9atYfrdyZNDv8irr26/kHPbtnDzzWEisFSuAyoimdMkEj2EqV8nTQrJ/pxz4D//UeKpj5UrQ6190iR46aUwTwyEE5Euvjh0pGrOIZH80GQSPYQk9PTToZN22LAwd7hOf09OVVXo63juuZDcy8vDqJnOncOwx1itfb/9ch2piFTXpBI9wPHHw113wejRYTbC227LdUT5xx2WLg1zqE+bFsa0z5oVyjHNmoWW+i9+Ea52dMQROgNVJN81uUQPcOml4apAv/tdmEP84ovr3qaQffFFaKHPmBFm/nzrrdB5DWGoY79+8L//GyaMO/XUMO2AiDQeTTLRQ5gm4b334HvfCyNxTjop1xFl1/LlYU6gZ54JJ5Nt2hSW9+wZ5oo5/vhwO/RQlbdEGrsmm+hbtoSnngrJbOjQMFqkpICvf+UepvB9+ukwpv3NN8Py9u23D3ksLq77WqUi0vg02UQPsPvu8O9/hzHdp50WhgcWF+c6qsxZty6cQ/DXv4b5fjZuDMv79IFbbw3TDPTtG+ZlF5HC1aQTPYQLOL/ySrgAxSmnhJb94YfnOqr0vftuSOwLFoQPsXXrwhWULr8cuncPI2MOS3j5GBEpRE0+0UO4dNzLL8PgwSHZv/JK40mGW7eGM0+feir8DvPmhZp6jx5h3phrry3skpSI1E2JPnLAAduT/UknhbM7Dzkk11HV7u23Q2fy/Pnh7N/jjw/19tJSKCrKdXQiki+U6OP06rVzss+ni5Z8+WXoR3juudCKf++9cILSo4+GzlTN+igiNVGir+agg3ZM9lOnhtZ+rnz0UUjs//pX+ODZuDFcfGPQoHDZxMsuC9dDFRFJRIm+BgcfHJL9oEFh6OXbb2e/tTxlClx9dZjiF8IH0BVXwFlnhRJNq1bZjUdEGi8l+gQOPTScSHTGGaHuXVbWsFeoWrkyfHuYOjUk+ZkzwyiZcePCJGy5/FYhIo1bwcxSUlYWRpo0axZ+lpXVf5+nngq/+lU4wejOO+u/v3ju4RJ6l14avkHstVe45OH48eGiHLfdFjpZr7pKSV5E6ieZi4M/CJwDrHT3nQYdmtlg4B/A4mjRU+5+S/TcGcAfgObA/e7+2wzFvYOyMhg1CjZsCI+XLg2PIYxAqY8f/zhMaXzddWHI5ckn129/mzaFbwp33AFz54b6+vHHh7lkBg0Kk4SpLCMimVTnxcHNbBCwHniklkR/nbufU215c+AD4FRgGTANGObu8+sKKtWLg/foEZJ7dZ06weefJ72bhNauDfO/fPQRPPlkGJ+eis8+C6NlJk8OUxB88UUoDV13XZguuXXr+scoIk1bbRcHr7N04+5TgNVpvO4AYKG7L3L3TcAEYEga+6nTf/9b8/KKisyUcHbbLYx4OfRQOPdc+NGP4NNPE6/vDh98EFrtAwfCPvuEbxZPPhk6UydNCq35ESOU5EWk4WWqM/YYM5sNfEJo3c8DugAfx62zDEh4zSEzGwWMAujWrVtKL96tW80teghDEKH+JZyionDG7E03hfns77orzIsTm5O9Y8cwadgbb4SpBxZHhazi4jB3+1lnhel+NROkiGRbJhL9DKC7u683s7OAvwO9Ut2Ju48HxkMo3aSy7a23Jp5Tvqoqc/X6Dh1Cp+zo0eEatJMmhU7Tqqrt67RrF+r4118fknv37vV7TRGR+qqzRg9gZj2Af9ZUo69h3SVACSHZj3X306PlPwFw99/UtY9Ua/QQWtwVFYmfz1S9vrrKylC7X706lGgOOECdqSKSffWq0Sex873NwghzMxsQ7bOC0Pnay8x6mlkr4CLgmfq+XiJ/+AO0bZv4+UzV66vr0CGUZE46KQyTVJIXkXyTzPDKx4HBQJGZLQPGAC0B3P0+4ALgMjPbAnwFXOTha8IWM/sh8DxheOWDUe2+QcTKMsOH71hKiZeper2ISGOSVOkm29Ip3cSUldV+Ddi2bcNJSUr2IlJIGrR0k29KS2u/ePWGDeFsUxGRpqLgEj0kV68vKmqYmr2ISL4pyEnNkqnXV1RkbtiliEg+K8gWPYTk/fDDta+jMo6INAUFm+ih7no9NNywSxGRfFHQiR7qrtdDKPEo2YtIoSr4RF9aGoZT1tayj02ToGQvIoWo4BM9hGT/+ed1D7tUy15EClGTSPQxdZVx1LIXkULUpBJ9rIxT21TBGokjIoWmSSV62D7sMhcToImI5EJBnjBVF02AJiJNSZNM9LA9gWfjgiUiIrnU5Eo38TQBmog0BU060UPuLlgiIpItTbZ0E6N6vYgUuiaf6EH1ehEpbE2+dBOjer2IFCol+jiq14tIIaoz0ZvZg2a20szeTfB8qZnNMbO5ZvammR0e99ySaPksM0vvIrBZlMyZs5oPR0Qam2Ra9H8Gzqjl+cXACe7eB/glML7a8ye6e79EF63NN3VdsKSqCi65BC6/PHsxiYjUR52J3t2nAKtref5Nd/8ievg20DVDseVMXfV6d7jvPrXsRaRxyHSN/nvApLjHDrxgZtPNbFRtG5rZKDMrN7PyVatWZTis1NVVr3dXGUdEGoeMDa80sxMJif64uMXHuftyM9sTeNHMFkTfEHbi7uOJyj4lJSWeqbjSlcz4eg27FJHGICMtejPrC9wPDHH3ithyd18e/VwJPA0MyMTrZUusXm+WeB0NuxSRfFfvRG9m3YCngEvc/YO45e3MrEPsPnAaUOPInXxWWgqjR9ee7CsqoKhIZRwRyU91lm7M7HFgMFBkZsuAMUBLAHe/D7gZ6ATcYyEbbolG2OwFPB0tawE85u7/boDfocHdcw8MHFh7GaeiQmUcEclP5p7zcvhOSkpKvLw8/4bdl5UlniYhplOncH1aEZFsMrPpiYax68zYFNQ17BJUxhGR/KNEn6K6hl1CSPY6qUpE8oUSfYpi0yTU1bJ3h3vvVeteRHJPiT4NpaWhDl9XsofQur/4YiV8EckdJfp6SKaMExNL+GbQo4eSvohkjxJ9PSRbxqlu6VLV8EUke5To6ylWxrnsstpPqqpONXwRyRYl+gy55x549NHUW/cq6YhIQ1Oiz6BY6/4vf0k94UMo6Sjpi0imKdE3gHTLOfFUxxeRTFGib0Cxck737ultH6vjm6mWLyLpU6JvYKWlsGRJSNrplnRA4/FFJH1K9FmUiZKOOm9FJFVK9DlQ35JOjDpvRSQZSvQ5Ur2kk8mkr/KOiMRTos8Dmarjx6ieLyLxlOjzTH3H4sdTPV9EQIk+b8USvnv9Om9jNC5fpOlKKtGb2YNmttLMary4twV3mtlCM5tjZkfEPTfczD6MbsMzFXhTkqnOW43LF2makm3R/xk4o5bnzwR6RbdRwL0AZtaRcDHxo4ABwBgz2yPdYJuyRJ239R2mqYQvUviSSvTuPgVYXcsqQ4BHPHgb2N3M9gFOB15099Xu/gXwIrV/YEgS4pP+1q2ZORFLdXyRwpWpGn0X4OO4x8uiZYmWSwZlqp6vOr5IYcqbzlgzG2Vm5WZWvmrVqlyH02hlan4dlXRECkemEv1yYL+4x12jZYmW78Tdx7t7ibuXdO7cOUNhNU2ZGJevko5I4chUon8G+G40+uZoYK27rwCeB04zsz2iTtjTomWSJZkYl6+SjkjjluzwyseBt4CDzGyZmX3PzEab2eholeeARcBC4E/A5QDuvhr4JTAtut0SLZMsq28dXyUdkcbL3D3XMeykpKTEy8vLcx1GQSsrg5tuCq31dHTqBH/4Q/gAEZHcM7Pp7l5S03N50xkr2VXfOr5q+CKNhxK91HuefNXwRfKbEr1sU5+hmarhi+QvJXrZQSZKOmrdi+QXJXpJKN2hmWrdi+QXJXqpU7o1fLXuRfKDEr0kLZ0avlr3IrmnRC8pSbeGr9a9SO4o0UvaUi3pqHUvkhtK9FJvsZKOWvci+UmJXjIi3da9Lmso0vCU6CWjUm3dQ2jhjxypZC/SUJToJePSGY65aRMMH65kL9IQlOilwaTauq+q0kRpIg1BiV4aVLonWy1dGpK+6vci9adEL1mRTu0eQv1+1Cgle5H6UKKXrEl37pwNG+CqqxouLpFCp0QvWRef8JMt51RUqIwjki4lesmZ0lIYPTq1ZK8TrURSl+zFwc8ws/fNbKGZ3VjD8/+/mc2Kbh+Y2Zq456rinnsmk8FL41d9orS6kr6mURBJXZ0XBzez5sAHwKnAMmAaMMzd5ydY/0dAsbuPjB6vd/f2qQSli4M3bUVFofVeF7PwjeCeexo+JpF8V9+Lgw8AFrr7InffBEwAhtSy/jDg8dTDFAn+8Ado27bu9dS6F0lOMom+C/Bx3ONl0bKdmFl3oCfwctziNmZWbmZvm9nQtCOVJqO0FMaP1yRpIpmS6c7Yi4An3b0qbln36OvEd4BxZnZATRua2ajoA6F81apVGQ5LGhtNgSySOckk+uXAfnGPu0bLanIR1co27r48+rkIeBUormlDdx/v7iXuXtK5c+ckwpKmQFMgi9RfMol+GtDLzHqaWStCMt9p9IyZ9Qb2AN6KW7aHmbWO7hcBA4EaO3FFElHrXqR+6kz07r4F+CHwPPAe8IS7zzOzW8zsvLhVLwIm+I7DeA4Gys1sNvAK8NtEo3VE6pJO617TJ4gkMbwyFzS8Uupy+eVw332h9V6XTp3CNwKRQlbf4ZUieSeV1r2mT5CmToleGq1UavfqpJWmTIleGr1kW/fqpJWmSoleCkKsdZ9sKUete2lKlOiloGj6BJGdKdFLQUln+gRdslAKnRK9FJx0rlOrco4UMiV6KVipnmClco4UKiV6KWhq3Yso0UsToda9NGVK9NJkxF+UXPPlSFOiRC9NTqrlnA0bwsicHj2U8KVxUqKXJivVcs7SpWrdS+OkRC9NWjqt+6uuavi4RDJJiV4EzYYphU2JXiSi+XKkUCnRi1Sj+XKk0CjRi1QTmy+ne/fk1lfrXvKdEr1IDUpLYcmSMOZerXtp7JJK9GZ2hpm9b2YLzezGGp4fYWarzGxWdPt+3HPDzezD6DY8k8GLNLR0ZsNU617yTZ2J3syaA3cDZwKHAMPM7JAaVp3o7v2i2/3Rth2BMcBRwABgjJntkbHoRbIg1SGYat1LvkmmRT8AWOjui9x9EzABGJLk/k8HXnT31e7+BfAicEZ6oYrkVqonWKl1L/kimUTfBfg47vGyaFl13zKzOWb2pJntl+K2mNkoMys3s/JVq1YlEZZI9qXTur/vPrXsJbcy1Rn7LNDD3fsSWu0Pp7oDdx/v7iXuXtK5c+cMhSXSMFJp3bvD8OFK9pI7yST65cB+cY+7Rsu2cfcKd98YPbwfODLZbUUaq1Ra91VVYWI0M9XuJfuSSfTTgF5m1tPMWgEXAc/Er2Bm+8Q9PA94L7r/PHCame0RdcKeFi0TKRjp1O51nVrJpjoTvbtvAX5ISNDvAU+4+zwzu8XMzotWu9LM5pnZbOBKYES07Wrgl4QPi2nALdEykYKiK1lJPjN3z3UMOykpKfHy8vJchyGSlrKyUJOvqkp+m06dwtQLpaUNF5cUNjOb7u4lNT2nM2NFMqy0FB5+OLkzamPUupeGpEQv0gBSPaMWdKKVNBwlepEGks41amF7Z62ZLl8omaFEL9LAYgnfPbXOWgiXL1RJR+pLiV4ki1Idigkq6Uj9KdGLZFk6QzFBHbaSPiV6kRypT+teZ9hKKpToRXIo3dY96AxbSV6jOWFq8+bNLFu2jK+//jpHUUmy2rRpQ9euXWnZsmWuQ2lUysrgpptCB2y6uneHW2/ViVdNUW0nTDWaRL948WI6dOhAp06dsFSbPpI17k5FRQWVlZX07Nkz1+E0WmVlcNVVodWeDp1p2/QUxJmxX3/9tZJ8I2BmdOrUSd+86qk+JR3QWHzZUaNJ9ICSfCOh9ylz0umwrW7pUiX9pq5RJXqRpijdM2xroqTfNBVsoi8rC3/IzZrV/w+6oqKCfv360a9fP/bee2+6dOmy7fGmTUbgOQcAAA+8SURBVJtq3ba8vJwrr7yyztc49thj0w8wzquvvso555yTkX1JfqnPGbY10Vm3TUdBJvqyMhg1Kvwhu4efo0aln+w7derErFmzmDVrFqNHj+aaa67Z9rhVq1Zs2bIl4bYlJSXceeeddb7Gm2++mV5w0iTFSjrdu4fH6SZ9jctvGgoy0d90E2zYsOOyDRvC8kwZMWIEo0eP5qijjuKGG27gnXfe4ZhjjqG4uJhjjz2W999/H9ixhT127FhGjhzJ4MGD2X///Xf4AGjfvv229QcPHswFF1xA7969KS0tJTYy6rnnnqN3794ceeSRXHnllXW23FevXs3QoUPp27cvRx99NHPmzAHgtdde2/aNpLi4mMrKSlasWMGgQYPo168fhx12GFOnTs3cwZIGUVoKS5aEZL11a/1b+fEduEr6haUgE/1//5va8nQtW7aMN998k9///vf07t2bqVOnMnPmTG655RZ++tOf1rjNggULeP7553nnnXf4xS9+webNm3daZ+bMmYwbN4758+ezaNEi3njjDb7++msuvfRSJk2axPTp01m1alWd8Y0ZM4bi4mLmzJnDr3/9a7773e8CcMcdd3D33Xcza9Yspk6dyi677MJjjz3G6aefzqxZs5g9ezb9+vWr38GRrKveyq8PJf3CUpCJvlu31Jan68ILL6R58+YArF27lgsvvJDDDjuMa665hnnz5tW4zdlnn03r1q0pKipizz335LPPPttpnQEDBtC1a1eaNWtGv379WLJkCQsWLGD//fffNjZ92LBhdcb3+uuvc8kllwBw0kknUVFRwbp16xg4cCDXXnstd955J2vWrKFFixb079+fhx56iLFjxzJ37lw6dOiQ7mGRHIpv5f/lL5lP+s2bqyO3MSrIRH/rrTtf3adt27A8k9q1a7ft/s9//nNOPPFE3n33XZ599tmE48hbt2697X7z5s1rrO8ns0593Hjjjdx///189dVXDBw4kAULFjBo0CCmTJlCly5dGDFiBI888khGX1OyryGS/tat4Wds9I5a+41DUonezM4ws/fNbKGZ3VjD89ea2Xwzm2Nmk82se9xzVWY2K7o9k8ngE4ld3ad799D66N49PG7IswTXrl1Lly5dAPjzn/+c8f0fdNBBLFq0iCVLlgAwceLEOrc5/vjjKYv+C1999VWKiorYdddd+eijj+jTpw8//vGP6d+/PwsWLGDp0qXstdde/OAHP+D73/8+M2bMyPjvILlTPenXd5hmTHxrX2We/FVnojez5sDdwJnAIcAwMzuk2mozgRJ37ws8Cfwu7rmv3L1fdDsvQ3HXKfaHvXVr+NnQp4LfcMMN/OQnP6G4uDjjLXCAXXbZhXvuuYczzjiDI488kg4dOrDbbrvVus3YsWOZPn06ffv25cYbb+Thhx8GYNy4cRx22GH07duXli1bcuaZZ/Lqq69y+OGHU1xczMSJE7nqqqsy/jtIfsjkuPzqVNvPT3XOdWNmxwBj3f306PFPANz9NwnWLwbucveB0eP17t4+laBqmuvmvffe4+CDD05lNwVn/fr1tG/fHnfniiuuoFevXlxzzTW5DqtGer8al/rOrZMKzcPTMOo7100X4OO4x8uiZYl8D5gU97iNmZWb2dtmNrSWIEdF65UnM6KkKfrTn/5Ev379OPTQQ1m7di2XXnpprkOSAhF/MlZDtPTjqdWffRntjDWzi4ES4Pa4xd2jT5nvAOPM7ICatnX38e5e4u4lnTt3zmRYBSN2otb8+fMpKyujbfUeZ5EMyFXS14iehpNMol8O7Bf3uGu0bAdmdgpwE3Ceu2+MLXf35dHPRcCrQHE94hWRLIpP+rFbJqZfqEn1ET1mYQoTdfTWXzKJfhrQy8x6mlkr4CJgh9EzUV3+j4QkvzJu+R5m1jq6XwQMBOZnKngRyb5MTb+QjPguRJV80ldnonf3LcAPgeeB94An3H2emd1iZrFRNLcD7YG/VhtGeTBQbmazgVeA37q7Er1II1d9+oVslHniVR/WWdNNHwbbNZorTGkUR+Oi96tpy+YonmQ0axY+kAr5UosFcYWpXDvxxBN5/vnnd1g2btw4LrvssoTbDB48mNgH1llnncWaNWt2Wmfs2LHccccdtb723//+d+bP3/5F6Oabb+all15KJfwaaUpjaSg11faz3eqPV1P9P74DuEWLwu4IVqJP0rBhw5gwYcIOyyZMmJDUnDMQZp7cfffd03rt6on+lltu4ZRTTklrXyK5lM0RPcmIfQBUVYWfiT4IGvsHQKNM9FdfDYMHZ/Z29dW1v+YFF1zAv/71r20XGlmyZAmffPIJxx9/PJdddhklJSUceuihjBkzpsbte/Toweeffw7ArbfeyoEHHshxxx23bTpjCOPk+/fvz+GHH863vvUtNmzYwJtvvskzzzzD9ddfT79+/fjoo48YMWIETz75JACTJ0+muLiYPn36MHLkSDZu3Ljt9caMGcMRRxxBnz59WLBgQa2/n6Y0lmyr3uqPn48nmiuwQTt6k5Hom0Bj6wtolIk+Fzp27MiAAQOYNCmcCzZhwgS+/e1vY2bceuutlJeXM2fOHF577bVtSbIm06dPZ8KECcyaNYvnnnuOadOmbXvu/PPPZ9q0acyePZuDDz6YBx54gGOPPZbzzjuP22+/nVmzZnHAAdtPQ/j6668ZMWIEEydOZO7cuWzZsoV777132/NFRUXMmDGDyy67rM7ykKY0llyL7+DdsiV3Hb2pqulcgKKicMvEFe4yoUVuXz4948bl5nVj5ZshQ4YwYcIEHnjgAQCeeOIJxo8fz5YtW1ixYgXz58+nb9++Ne5j6tSpfPOb39x2stN5522f/ufdd9/lZz/7GWvWrGH9+vWcfvrptcbz/vvv07NnTw488EAAhg8fzt13383V0deT888/H4AjjzySp556qtZ9vf766/ztb38Dap7SuLS0lPPPP5+uXbvSv39/Ro4cyebNmxk6dKgSvTS40tLtHaj51tEbL/YNID622LeB2IdBTeNfGnpaCLXoUzBkyBAmT57MjBkz2LBhA0ceeSSLFy/mjjvuYPLkycyZM4ezzz474RTFdRkxYgR33XUXc+fOZcyYMWnvJyY23XF9pjrWlMaSbxJ19OZDp29dEg1ybOhzBJToU9C+fXtOPPFERo4cua0Tdt26dbRr147ddtuNzz77bFtpJ5FBgwbx97//na+++orKykqeffbZbc9VVlayzz77sHnz5m3TCwN06NCBysrKnfZ10EEHsWTJEhYuXAjAo48+ygknnJDW76YpjaWQ1Fb/j6/7N8vDDFhRASNHZjbZ5+Gvmd+GDRvG7NmztyX62NS+vXv35jvf+Q4DBw6sdfsjjjiC//mf/+Hwww/nzDPPpH///tue++Uvf8lRRx3FwIED6d2797blF110EbfffjvFxcV89NFH25a3adOGhx56iAsvvJA+ffrQrFkzRo8endbvpSmNpZDVdIKXexhtU9sHQa5s2pTZa1zrhClpEHq/pBCUlYWEu3Rp4vp6QzHbXvNPbn2dMCUikrJE3wSy0ReQyWtcK9GLiKQpUV+AWfgAiH0IpHpeQKtWmb3GdaNK9PlYZpKd6X2Spir+Eqaff779Q6D6eQG1fSvo1AkefDCzQy0bzTj6Nm3aUFFRQadOnbB86C2RGrk7FRUVtGnTJtehiDQK8ecINJRGk+i7du3KsmXL0GUG81+bNm3o2rVrrsMQkUijSfQtW7akZ8+euQ5DRKTRaVQ1ehERSZ0SvYhIgVOiFxEpcHl5ZqyZrQKWprl5EfB5BsPJFMWVunyNTXGlRnGlLp3Yurt755qeyMtEXx9mVp7oNOBcUlypy9fYFFdqFFfqMh2bSjciIgVOiV5EpMAVYqIfn+sAElBcqcvX2BRXahRX6jIaW8HV6EVEZEeF2KIXEZE4SvQiIgWuYBK9mZ1hZu+b2UIzuzGHcexnZq+Y2Xwzm2dmV0XLx5rZcjObFd3OylF8S8xsbhRDebSso5m9aGYfRj/3yHJMB8Udl1lmts7Mrs7FMTOzB81spZm9G7esxuNjwZ3R39wcMzsiB7HdbmYLotd/2sx2j5b3MLOv4o7dfVmOK+F7Z2Y/iY7Z+2Z2epbjmhgX0xIzmxUtz+bxSpQjGu7vzN0b/Q1oDnwE7A+0AmYDh+Qoln2AI6L7HYAPgEOAscB1eXCslgBF1Zb9Drgxun8jcFuO38tPge65OGbAIOAI4N26jg9wFjAJMOBo4D85iO00oEV0/7a42HrEr5eDuGp876L/hdlAa6Bn9H/bPFtxVXv+/wNuzsHxSpQjGuzvrFBa9AOAhe6+yN03AROAIbkIxN1XuPuM6H4l8B7QJRexpGAI8HB0/2FgaA5jORn4yN3TPTO6Xtx9CrC62uJEx2cI8IgHbwO7m9k+2YzN3V9w9y3Rw7eBrM8PneCYJTIEmODuG919MbCQ8P+b1bgsXNTi28DjDfHataklRzTY31mhJPouwMdxj5eRB8nVzHoAxcB/okU/jL56PZjt8kgcB14ws+lmNipatpe7r4jufwrslZvQALiIHf/58uGYJTo++fZ3N5LQ8ovpaWYzzew1Mzs+B/HU9N7lyzE7HvjM3T+MW5b141UtRzTY31mhJPq8Y2btgb8BV7v7OuBe4ACgH7CC8LUxF45z9yOAM4ErzGxQ/JMevivmZMytmbUCzgP+Gi3Kl2O2TS6PT23M7CZgC1AWLVoBdHP3YuBa4DEz2zWLIeXde1fNMHZsUGT9eNWQI7bJ9N9ZoST65cB+cY+7RstywsxaEt7AMnd/CsDdP3P3KnffCvyJBvq6Whd3Xx79XAk8HcXxWeyrYPRzZS5iI3z4zHD3z6IY8+KYkfj45MXfnZmNAM4BSqMEQVQaqYjuTyfUwg/MVky1vHc5P2Zm1gI4H5gYW5bt41VTjqAB/84KJdFPA3qZWc+oVXgR8EwuAolqfw8A77n77+OWx9fUvgm8W33bLMTWzsw6xO4TOvLeJRyr4dFqw4F/ZDu2yA6trHw4ZpFEx+cZ4LvRqIijgbVxX72zwszOAG4AznP3DXHLO5tZ8+j+/kAvYFEW40r03j0DXGRmrc2sZxTXO9mKK3IKsMDdl8UWZPN4JcoRNOTfWTZ6mbNxI/RMf0D4JL4ph3EcR/jKNQeYFd3OAh4F5kbLnwH2yUFs+xNGPMwG5sWOE9AJmAx8CLwEdMxBbO2ACmC3uGVZP2aED5oVwGZCLfR7iY4PYRTE3dHf3FygJAexLSTUb2N/a/dF634reo9nATOAc7McV8L3DrgpOmbvA2dmM65o+Z+B0dXWzebxSpQjGuzvTFMgiIgUuEIp3YiISAJK9CIiBU6JXkSkwCnRi4gUOCV6EZECp0QvIlLglOhFRArc/wN9po9zQVA9pgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_44LGpK-xx4"
      },
      "source": [
        "def final_predictions(text):\n",
        "  y_id_to_word = {value: key for key, value in french_tokenizer.word_index.items()}\n",
        "  y_id_to_word[0] = '<PAD>'\n",
        "\n",
        "  sentence = [english_tokenizer.word_index[word] for word in text.split()]\n",
        "  sentence = pad_sequences([sentence], maxlen=preproc_french_sentences.shape[-2], padding='post')\n",
        "  \n",
        "  print(sentence.shape)\n",
        "  print(logits_to_text(simple_rnn_model.predict(sentence[:1])[0], french_tokenizer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr8pT-bX4MpG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm-DAR9H-4xD"
      },
      "source": [
        "simple_rnn_model.save('model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onnTqdkf-_ry"
      },
      "source": [
        "! mkdir \"pickles\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhDpg-NB_AXV"
      },
      "source": [
        "with open('pickles/french_tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(french_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('pickles/english_tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(english_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('pickles/preproc_french_sentences.pickle', 'wb') as handle:\n",
        "    pickle.dump(preproc_french_sentences, handle, protocol=pickle.HIGHEST_PROTOCOL) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}